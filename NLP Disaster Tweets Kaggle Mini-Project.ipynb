{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: NLP Disaster Tweets Kaggle Mini-Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief description of the problem and data (5 pts)\n",
    "\n",
    "*Briefly describe the challenge problem and NLP. Describe the size, dimension, structure, etc., of the data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA) — Inspect, Visualize and Clean the Data (15 pts)\n",
    "\n",
    "*Show a few visualizations like histograms. Describe any data cleaning procedures. Based on your EDA, what is your plan of analysis?*\n",
    "\n",
    "Checking the general structure of the data and potential duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************** Train dataset ****************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          7613 non-null   int64 \n",
      " 1   keyword     7552 non-null   object\n",
      " 2   location    5080 non-null   object\n",
      " 3   text        7613 non-null   object\n",
      " 4   target      7613 non-null   int64 \n",
      " 5   word_count  7613 non-null   int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 357.0+ KB\n",
      "\n",
      "Numerical statistics:\n",
      "                  id      target   word_count\n",
      "count   7613.000000  7613.00000  7613.000000\n",
      "mean    5441.934848     0.42966    14.903586\n",
      "std     3137.116090     0.49506     5.732604\n",
      "min        1.000000     0.00000     1.000000\n",
      "25%     2734.000000     0.00000    11.000000\n",
      "50%     5408.000000     0.00000    15.000000\n",
      "75%     8146.000000     1.00000    19.000000\n",
      "max    10873.000000     1.00000    31.000000\n",
      "\n",
      "    id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this earthquake Ma...   \n",
      "1   4     NaN      NaN              Forest fire near La Ronge Sask Canada   \n",
      "2   5     NaN      NaN  All residents asked to shelter in place are be...   \n",
      "3   6     NaN      NaN  13000 people receive wildfires evacuation orde...   \n",
      "\n",
      "   target  word_count  \n",
      "0       1          13  \n",
      "1       1           7  \n",
      "2       1          22  \n",
      "3       1           8   \n",
      "\n",
      "Number of duplicated rows: 0\n",
      "Number of duplicated texts: 652\n",
      "Longest tweet has 31 words.\n",
      "Unique words in the dataset: 21891\n",
      "Target values: [1 0]\n",
      "Target split: \n",
      "1 (disaster) = 43 %\n",
      "0 (not disaster) = 57 %\n",
      "\n",
      "**************************************** Test dataset ****************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          3263 non-null   int64 \n",
      " 1   keyword     3237 non-null   object\n",
      " 2   location    2158 non-null   object\n",
      " 3   text        3263 non-null   object\n",
      " 4   word_count  3263 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 127.6+ KB\n",
      "\n",
      "Numerical statistics:\n",
      "                  id   word_count\n",
      "count   3263.000000  3263.000000\n",
      "mean    5427.152927    14.965369\n",
      "std     3146.427221     5.783576\n",
      "min        0.000000     1.000000\n",
      "25%     2683.000000    11.000000\n",
      "50%     5500.000000    15.000000\n",
      "75%     8176.000000    19.000000\n",
      "max    10875.000000    31.000000\n",
      "\n",
      "    id keyword location                                               text  \\\n",
      "0   0     NaN      NaN                 Just happened a terrible car crash   \n",
      "1   2     NaN      NaN  Heard about earthquake is different cities sta...   \n",
      "2   3     NaN      NaN  there is a forest fire at spot pond geese are ...   \n",
      "3   9     NaN      NaN              Apocalypse lighting Spokane wildfires   \n",
      "\n",
      "   word_count  \n",
      "0           6  \n",
      "1           9  \n",
      "2          19  \n",
      "3           4   \n",
      "\n",
      "Number of duplicated rows: 0\n",
      "Number of duplicated texts: 157\n",
      "Longest tweet has 31 words.\n",
      "Unique words in the dataset: 12889\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def count_words(df):\n",
    "    for i, row in df.iterrows():\n",
    "        df.loc[i, 'word_count'] = len(row.text.split())\n",
    "        txt = df.loc[i, 'text']\n",
    "        txt = re.sub(r'https?://\\S+|www.\\S+', '', txt) # Remove URLs\n",
    "        txt = re.sub(r'[^a-z0-9A-Z\\s]', '', txt) # Remove numbers\n",
    "        # txt = txt.lower()\n",
    "        df.loc[i, 'text'] = txt\n",
    "    df['word_count'] = df['word_count'].astype(int)\n",
    "    all_text = ' '.join(df.text)\n",
    "    unique_words = len(set(all_text.split()))\n",
    "    return unique_words\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "train_unique_words = count_words(train_df)\n",
    "test_unique_words = count_words(test_df)\n",
    "\n",
    "all_text = ' '.join(((pd.concat([train_df,test_df], axis=0)).text.values))\n",
    "all_unique_words = len(set(all_text.split()))\n",
    "\n",
    "\n",
    "print('\\n' + 40*'*' + ' Train dataset ' + 40*'*')\n",
    "train_df.info()\n",
    "print('\\nNumerical statistics:\\n', train_df.describe())\n",
    "print('\\n', train_df.head(4), '\\n')\n",
    "# print('\\n', train_df.tail(3))\n",
    "print('Number of duplicated rows:', np.sum(train_df.duplicated()))\n",
    "print('Number of duplicated texts:', np.sum(train_df.duplicated(subset='text')))\n",
    "print('Longest tweet has', np.max(train_df.word_count), 'words.')\n",
    "print('Unique words in the dataset:', train_unique_words)\n",
    "print('Target values:', pd.unique(train_df.target))\n",
    "y_split = round(100 * np.sum(train_df.target == 1)/len(train_df.target))\n",
    "print('Target split: \\n1 (disaster) =', y_split, '%\\n0 (not disaster) =', 100-y_split, '%')\n",
    "\n",
    "print('\\n' + 40*'*' + ' Test dataset ' + 40*'*')\n",
    "test_df.info()\n",
    "print('\\nNumerical statistics:\\n', test_df.describe())\n",
    "print('\\n', test_df.head(4), '\\n')\n",
    "# print('\\n', test_df.tail(3))\n",
    "print('Number of duplicated rows:', np.sum(test_df.duplicated()))\n",
    "print('Number of duplicated texts:', np.sum(test_df.duplicated(subset='text')))\n",
    "print('Longest tweet has', np.max(test_df.word_count), 'words.')\n",
    "print('Unique words in the dataset:', test_unique_words)\n",
    "\n",
    "\n",
    "sns.histplot(train_df, x='word_count', bins=30, stat='percent')\n",
    "sns.histplot(test_df, x='word_count', bins=30, stat='percent')\n",
    "plt.grid(axis='y')\n",
    "plt.title('Histogram of approximate word counts in the data')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size with duplicated texts: 7613\n",
      "Size without duplicated texts: 6961\n"
     ]
    }
   ],
   "source": [
    "print('Size with duplicated texts:', len(train_df))\n",
    "train_df.drop_duplicates(subset='text', inplace=True)\n",
    "print('Size without duplicated texts:', len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture (25 pts)\n",
    "\n",
    "*Describe your model architecture and reasoning for why you believe that specific architecture would be suitable for this problem.*\n",
    "\n",
    "*Since we did not learn NLP-specific techniques such as word embeddings in the lectures, we recommend looking at Kaggle tutorials, discussion boards, and code examples posted for this challenge.  You can use any resources needed, but make sure you “demonstrate” you understood by including explanations in your own words. Also importantly, please have a reference list at the end of the report.*\n",
    "\n",
    "*There are many methods to process texts to matrix form (word embedding), including TF-IDF, GloVe, Word2Vec, etc. Pick a strategy and process the raw texts to word embedding. Briefly explain the method(s) and how they work in your own words.*\n",
    "\n",
    "*Build and train your sequential neural network model (You may use any RNN family neural network, including advanced architectures LSTM, GRU, bidirectional RNN, etc.).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 300\n",
    "max_features = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6961, 300)\n",
      "Min and max: 0 9999\n"
     ]
    }
   ],
   "source": [
    "my_vectorizer = keras.layers.TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    "    ngrams=2,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=None,\n",
    "    pad_to_max_tokens=None,\n",
    "    vocabulary=None,\n",
    "    idf_weights=None,\n",
    "    sparse=False,\n",
    "    ragged=False,\n",
    "    encoding=\"utf-8\",\n",
    "    name=None,\n",
    ")\n",
    "my_vectorizer.adapt(train_df['text'])\n",
    "x_train = my_vectorizer(train_df['text'])\n",
    "\n",
    "x_train = keras.utils.pad_sequences(x_train, maxlen=maxlen)\n",
    "# x_test = keras.utils.pad_sequences(x_test, maxlen=maxlen)\n",
    "y_train = train_df.target\n",
    "\n",
    "print('Shape:', x_train.shape)\n",
    "print('Min and max:', np.min(x_train), np.max(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to shelter in place are be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7602</th>\n",
       "      <td>a siren just went off and it wasnt the Forney ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>Officials say a quarantine is in place at an A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7604</th>\n",
       "      <td>WorldNews Fallen powerlines on Glink tram UPDA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>on the flip side Im at Walmart and there is a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7606</th>\n",
       "      <td>Suicide bomber kills 15 in Saudi security site...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6961 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text keyword location\n",
       "0     Our Deeds are the Reason of this earthquake Ma...     NaN      NaN\n",
       "1                 Forest fire near La Ronge Sask Canada     NaN      NaN\n",
       "2     All residents asked to shelter in place are be...     NaN      NaN\n",
       "3     13000 people receive wildfires evacuation orde...     NaN      NaN\n",
       "4     Just got sent this photo from Ruby Alaska as s...     NaN      NaN\n",
       "...                                                 ...     ...      ...\n",
       "7602  a siren just went off and it wasnt the Forney ...     NaN      NaN\n",
       "7603  Officials say a quarantine is in place at an A...     NaN      NaN\n",
       "7604  WorldNews Fallen powerlines on Glink tram UPDA...     NaN      NaN\n",
       "7605  on the flip side Im at Walmart and there is a ...     NaN      NaN\n",
       "7606  Suicide bomber kills 15 in Saudi security site...     NaN      NaN\n",
       "\n",
       "[6961 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[:,['text','keyword','location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (6961, 2825)\n",
      "Shape of y_train: (6961,)\n",
      "Length of ftr_names: 2825\n",
      "ftr_names: ['05' '06' '10' ... 'yyc' 'zombie' 'zone']\n",
      "Shape of X_test: (3263, 2825)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object BaseShuffleSplit.split at 0x0000021BC12C6740>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.95, min_df=2, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "# my_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.95, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 1), stop_words='english')\n",
    "# my_vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "my_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.95, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english', max_features=max_features)\n",
    "my_vectorizer.fit(train_df.text)\n",
    "x_data = my_vectorizer.transform(train_df['text'])\n",
    "x_train = x_data\n",
    "y_train = train_df.target\n",
    "\n",
    "print('Shape of x_train:', x_train.shape)\n",
    "print('Shape of y_train:', y_train.shape)\n",
    "\n",
    "ftr_names = my_vectorizer.get_feature_names_out()\n",
    "print('Length of ftr_names:',len(ftr_names))\n",
    "print('ftr_names:', my_vectorizer.get_feature_names_out())\n",
    "\n",
    "x_test = my_vectorizer.transform(test_df['text'])\n",
    "print('Shape of X_test:', x_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Tensor Flow data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_df.text.values, train_df.target.values))\n",
    "test_ds =  tf.data.Dataset.from_tensor_slices((test_df.text.values))\n",
    "all_txt = pd.concat([train_df.text, test_df.text], axis=0)\n",
    "train_test_ds = tf.data.Dataset.from_tensor_slices((all_txt.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Just happened a terrible car crash'\n",
      "b'Heard about earthquake is different cities stay sa'\n",
      "b'there is a forest fire at spot pond geese are flee'\n",
      "b'Apocalypse lighting Spokane wildfires'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Typhoon Soudelor kills 28 in China and Taiwan'\n",
      "1 \t b'Our Deeds are the Reason of this earthquake May AL'\n",
      "1 \t b'Forest fire near La Ronge Sask Canada'\n",
      "1 \t b'All residents asked to shelter in place are being '\n",
      "1 \t b'13000 people receive wildfires evacuation orders i'\n",
      "1 \t b'Just got sent this photo from Ruby Alaska as smoke'\n",
      "b'Our Deeds are the Reason of this earthquake May AL'\n",
      "b'Forest fire near La Ronge Sask Canada'\n",
      "b'All residents asked to shelter in place are being '\n",
      "b'13000 people receive wildfires evacuation orders i'\n",
      "b'Just got sent this photo from Ruby Alaska as smoke'\n"
     ]
    }
   ],
   "source": [
    "for txt in test_ds.take(5):\n",
    "    tf.print(txt.numpy()[ :50])\n",
    "for txt, trg in train_ds.take(5):\n",
    "    tf.print(trg, '\\t', txt.numpy()[ :50])\n",
    "for txt in train_test_ds.take(5):\n",
    "    tf.print(txt.numpy()[ :50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation size: 1522\n"
     ]
    }
   ],
   "source": [
    "text_count = len(train_df)\n",
    "val_size = int(text_count * 0.2)\n",
    "print('Validation size:', val_size)\n",
    "train_ds = train_ds.shuffle(text_count, reshuffle_each_iteration=False)\n",
    "val_ds = train_ds.take(val_size)\n",
    "train_ds = train_ds.skip(val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "10876\n",
      "(10876, 31)\n"
     ]
    }
   ],
   "source": [
    "all_unique_words\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=all_unique_words, split=' ', oov_token='<OOV>')\n",
    "\n",
    "# Fit the tokenizer on the sentences\n",
    "tokenizer.fit_on_texts(all_txt)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index['a'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(all_txt)\n",
    "print(len(sequences))\n",
    "\n",
    "padded_sequences = keras.preprocessing.sequence.pad_sequences(sequences, padding='post')\n",
    "print(padded_sequences.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1703"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_train(text_tensor, label):\n",
    "    text = text_tensor.numpy()[0]\n",
    "    encoded_text =  tokenizer.texts_to_sequences(text)\n",
    "    return encoded_text, label\n",
    "\n",
    "def encode_test(text_tensor):\n",
    "    text = text_tensor.numpy()[0]\n",
    "    encoded_text =  tokenizer.texts_to_sequences([text])\n",
    "    return encoded_text\n",
    "\n",
    "def encode_map_fn_train(text, label):\n",
    "    return tf.py_function(encode_train, inp=[text, label], Tout=(tf.int64, tf.int64))\n",
    "\n",
    "def encode_map_fn_test(text):\n",
    "    return tf.py_function(encode_test, inp=[text], Tout=(tf.int64))\n",
    "\n",
    "def _fixup_shape(text, label):\n",
    "    text.set_shape([])\n",
    "    label.set_shape([])\n",
    "    return text, label\n",
    "\n",
    "def _fixup_test_shape(text):\n",
    "    text.set_shape([])\n",
    "    return text\n",
    "\n",
    "# train_ds = train_ds.map(encode_map_fn_train)\n",
    "# val_ds = val_ds.map(encode_map_fn_train)\n",
    "test_ds = test_ds.map(encode_map_fn_test)\n",
    "# test_ds = test_ds.map(_fixup_test_shape)\n",
    "test_ds = test_ds.padded_batch(32, padded_shapes=([-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to MapDataset:771 transformation with iterator: Iterator::Root::Prefetch::FiniteTake::PaddedBatchV2::Map::PaddedBatchV2::Map: AttributeError: 'int' object has no attribute 'lower'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 267, in __call__\n    return func(device, token, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 145, in __call__\n    outputs = self._call(device, args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 152, in _call\n    ret = self._func(*args)\n          ^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Temp\\ipykernel_51080\\1837237296.py\", line 8, in encode_test\n    encoded_text =  tokenizer.texts_to_sequences([text])\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\preprocessing\\text.py\", line 177, in texts_to_sequences\n    return list(self.texts_to_sequences_generator(texts))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\preprocessing\\text.py\", line 192, in texts_to_sequences_generator\n    seq = text_to_word_sequence(\n          ^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\preprocessing\\text.py\", line 22, in text_to_word_sequence\n    input_text = input_text.lower()\n                 ^^^^^^^^^^^^^^^^\n\nAttributeError: 'int' object has no attribute 'lower'\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[192], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtxt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3113\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3111\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3113\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3115\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\framework\\ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mUnknownError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to MapDataset:771 transformation with iterator: Iterator::Root::Prefetch::FiniteTake::PaddedBatchV2::Map::PaddedBatchV2::Map: AttributeError: 'int' object has no attribute 'lower'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 267, in __call__\n    return func(device, token, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 145, in __call__\n    outputs = self._call(device, args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 152, in _call\n    ret = self._func(*args)\n          ^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Temp\\ipykernel_51080\\1837237296.py\", line 8, in encode_test\n    encoded_text =  tokenizer.texts_to_sequences([text])\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\preprocessing\\text.py\", line 177, in texts_to_sequences\n    return list(self.texts_to_sequences_generator(texts))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\preprocessing\\text.py\", line 192, in texts_to_sequences_generator\n    seq = text_to_word_sequence(\n          ^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\preprocessing\\text.py\", line 22, in text_to_word_sequence\n    input_text = input_text.lower()\n                 ^^^^^^^^^^^^^^^^\n\nAttributeError: 'int' object has no attribute 'lower'\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "for txt in test_ds.take(5):\n",
    "    tf.print(txt.numpy()[ :50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Sequences and their length:\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to MapDataset:663 transformation with iterator: Iterator::Root::Prefetch::FiniteTake::Map::Map: TypeError: 'int' object is not iterable\nTraceback (most recent call last):\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 267, in __call__\n    return func(device, token, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 145, in __call__\n    outputs = self._call(device, args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 152, in _call\n    ret = self._func(*args)\n          ^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Temp\\ipykernel_51080\\4172475293.py\", line 3, in encode_train\n    encoded_text =  tokenizer.texts_to_sequences(text)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\preprocessing\\text.py\", line 177, in texts_to_sequences\n    return list(self.texts_to_sequences_generator(texts))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\preprocessing\\text.py\", line 182, in texts_to_sequences_generator\n    for text in texts:\n                ^^^^^\n\nTypeError: 'int' object is not iterable\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample Sequences and their length:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m example \u001b[38;5;241m=\u001b[39m train_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIndividual Size: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatched examples and the sequence length:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3113\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3111\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3113\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3115\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\framework\\ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to MapDataset:663 transformation with iterator: Iterator::Root::Prefetch::FiniteTake::Map::Map: TypeError: 'int' object is not iterable\nTraceback (most recent call last):\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 267, in __call__\n    return func(device, token, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 145, in __call__\n    outputs = self._call(device, args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 152, in _call\n    ret = self._func(*args)\n          ^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Temp\\ipykernel_51080\\4172475293.py\", line 3, in encode_train\n    encoded_text =  tokenizer.texts_to_sequences(text)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\preprocessing\\text.py\", line 177, in texts_to_sequences\n    return list(self.texts_to_sequences_generator(texts))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\nikok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\preprocessing\\text.py\", line 182, in texts_to_sequences_generator\n    for text in texts:\n                ^^^^^\n\nTypeError: 'int' object is not iterable\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "print(\"Example Sequences and their length:\\n\")\n",
    "example = train_ds.take(8)\n",
    "for ex in example:\n",
    "    print(f\"Individual Size: {ex[0].shape}\")\n",
    "print(\"Batched examples and the sequence length:\\n\")\n",
    "batched_example = example.padded_batch(4, padded_shapes=([-1], []))\n",
    "for batch in batched_example:\n",
    "    print(f\"Batch dimension: {batch[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.padded_batch(32, padded_shapes=([-1], []))\n",
    "tweets_valid = tweets_valid.padded_batch(32, padded_shapes=([-1], []))\n",
    "tweets_unseen_batched = tweets_unseen_map.padded_batch(32, padded_shapes=([-1], []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building\n",
    "\n",
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,674,881</span> (6.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,674,881\u001b[0m (6.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,674,881</span> (6.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,674,881\u001b[0m (6.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input for variable-length sequences of integers\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "x = layers.Embedding(max_features, 128)(inputs)\n",
    "# Add 2 LSTMs\n",
    "x = layers.LSTM(128, return_sequences=True)(x)\n",
    "x = layers.LSTM(128, return_sequences=True)(x)\n",
    "x = layers.LSTM(128)(x)\n",
    "# Add a classifier\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bi-directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │     \u001b[38;5;34m3,840,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,037,761</span> (15.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,037,761\u001b[0m (15.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,037,761</span> (15.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,037,761\u001b[0m (15.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input for variable-length sequences of integers\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "x = layers.Embedding(max_features, 128)(inputs)\n",
    "# Add 2 bidirectional LSTMs\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "# Add a classifier\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_17 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_17 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m320,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m37,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">382,273</span> (1.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m382,273\u001b[0m (1.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">382,273</span> (1.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m382,273\u001b[0m (1.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input for variable-length sequences of integers\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "x = layers.Embedding(max_features, 128)(inputs)\n",
    "# Add 2 LSTMs\n",
    "# x = layers.LSTM(128, return_sequences=True)(x)\n",
    "x = layers.GRU(64, return_sequences=True)(x)\n",
    "x = layers.GRU(64)(x)\n",
    "# Add a classifier\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_3             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_3             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_5 (\u001b[38;5;33mGRU\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_6 (\u001b[38;5;33mGRU\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_7 (\u001b[38;5;33mGRU\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## https://www.kaggle.com/code/anmolstha/disaster-tweets-simple-rnn-implementation\n",
    "# Long Short Term Memory network.\n",
    "\n",
    "# We need sequential model to process sequence of text data\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Embedding(input_dimension, output_dimension,embeddings_initializer = initialize the embedding matrix we created, trainable = do not train)\n",
    "embedding= layers.Embedding(max_features, 100, trainable=False)\n",
    "# Adding Embedding Layer\n",
    "model.add(embedding)\n",
    "\n",
    "# Drops 40% of entire row\n",
    "model.add(layers.SpatialDropout1D(0.4))\n",
    "\n",
    "# Recurrent Layer LSTM(dimensionality of the output space, dropout = 20%, recurrent_dropout = 20%) \n",
    "model.add(layers.GRU(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(layers.GRU(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(layers.GRU(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "# Decide what we are going to output Dense(units, activation function)\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model compile(loss = binary crossentropy, use Adam(adaptive moment estimation) optimizer with learning rate 1e-3,evaluate based on accuracy)\n",
    "model.compile(loss='binary_crossentropy',optimizer=keras.optimizers.Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "\n",
    "max length = 1000\n",
    "\n",
    "3rd layer 0.5391\n",
    "\n",
    "256 dim 0.5391\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 399ms/step - accuracy: 0.5992 - loss: 0.6752 - val_accuracy: 0.5686 - val_loss: 0.6847\n",
      "Epoch 2/5\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 388ms/step - accuracy: 0.5948 - loss: 0.6755 - val_accuracy: 0.5686 - val_loss: 0.6836\n",
      "Epoch 3/5\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 385ms/step - accuracy: 0.5990 - loss: 0.6731 - val_accuracy: 0.5686 - val_loss: 0.6818\n",
      "Epoch 4/5\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 400ms/step - accuracy: 0.5983 - loss: 0.6735 - val_accuracy: 0.5686 - val_loss: 0.6818\n",
      "Epoch 5/5\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 442ms/step - accuracy: 0.5928 - loss: 0.6739 - val_accuracy: 0.5686 - val_loss: 0.6856\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "as_list() is not defined on an unknown TensorShape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mValueError\u001b[0m: as_list() is not defined on an unknown TensorShape."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_ds, batch_size=32, epochs=1, validation_data=val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.5957255959510803,\n",
       "  0.5957255959510803,\n",
       "  0.5957255959510803,\n",
       "  0.5957255959510803,\n",
       "  0.5957255959510803],\n",
       " 'loss': [0.6757225394248962,\n",
       "  0.6749722361564636,\n",
       "  0.6746339201927185,\n",
       "  0.6741043329238892,\n",
       "  0.6740113496780396],\n",
       " 'val_accuracy': [0.56855708360672,\n",
       "  0.56855708360672,\n",
       "  0.56855708360672,\n",
       "  0.56855708360672,\n",
       "  0.56855708360672],\n",
       " 'val_loss': [0.6847301721572876,\n",
       "  0.68359375,\n",
       "  0.6818068027496338,\n",
       "  0.681846559047699,\n",
       "  0.6856157779693604]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Analysis (35 pts)\n",
    "\n",
    "*Run hyperparameter tuning, try different architectures for comparison, apply techniques to improve training or performance, and discuss what helped.*\n",
    "\n",
    "*Includes results with tables and figures. There is an analysis of why or why not something worked well, troubleshooting, and a hyperparameter optimization procedure summary.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion (15 pts)\n",
    "\n",
    "*Discuss and interpret results as well as learnings and takeaways. What did and did not help improve the performance of your models? What improvements could you try in the future?*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "https://keras.io/examples/nlp/bidirectional_lstm_imdb/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
